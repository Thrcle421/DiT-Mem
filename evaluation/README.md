# Evaluation

This directory contains evaluation scripts and prompts for two text-to-video benchmarks: **PhyGenBench** and **VBench**.

## ğŸ“‚ Directory Structure

```
evaluation/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ phygenbench/                       # PhyGenBench evaluation
â”‚   â”œâ”€â”€ prompts.json                   # 160 evaluation prompts
â”‚   â”œâ”€â”€ generate_phygenbench_videos.py # Video generation script
â”‚   â””â”€â”€ run_phygenbench_evaluation.sh  # Bash wrapper script
â””â”€â”€ vbench/                            # VBench evaluation
    â”œâ”€â”€ prompts/                       # Prompt files directory
    â”‚   â””â”€â”€ *.txt                      # 11 category prompt files (10 prompts each)
    â”œâ”€â”€ generate_vbench_videos.py      # Video generation script
    â””â”€â”€ run_vbench_evaluation.sh       # Bash wrapper script
```

## ğŸ› ï¸ Prerequisites

Before running evaluations, ensure you have the following:

1.  **Trained Checkpoint**: `checkpoint/DiT-Mem-1.3B.safetensors`
2.  **Base Model**: `models/Wan2.1-T2V-1.3B`
3.  **Retrieval System**:
    *   Index: `memory_index/labels.index`
    *   Metadata: `memory_index/metadata.json`
    *   Videos: `videos/` (Directory containing memory bank videos)
    *   Latents: `latents/` (Pre-computed VAE latents)

## ğŸš€ PhyGenBench

[PhyGenBench](https://phygenbench.github.io/) evaluates the model's understanding of physical laws.

### Usage

1.  **Configure**: Open `phygenbench/run_phygenbench_evaluation.sh` and verify the paths in the configuration section.
    ```bash
    # Example configuration in script
    CHECKPOINT_PATH="checkpoint/DiT-Mem-1.3B.safetensors"
    BASE_MODEL="models/Wan2.1-T2V-1.3B"
    # ...
    ```

2.  **Run**:
    ```bash
    bash evaluation/phygenbench/run_phygenbench_evaluation.sh
    ```

3.  **Output**:
    *   Videos will be saved to `evaluation/phygenbench/outputs/`.
    *   Format: `video_output_1.mp4` to `video_output_160.mp4`.

## ğŸ“Š VBench

[VBench](https://vchitect.github.io/VBench-project/) provides a comprehensive evaluation of video generation quality across multiple dimensions.

### Usage

1.  **Configure**: Open `vbench/run_vbench_evaluation.sh` and verify the paths.
    *   You can optionally filter categories by setting the `CATEGORIES` variable (e.g., `CATEGORIES="scene color"`).

2.  **Run**:
    ```bash
    bash evaluation/vbench/run_vbench_evaluation.sh
    ```

3.  **Output**:
    *   Videos will be saved to `evaluation/vbench/outputs/`.
    *   Structure: Subdirectories for each category (e.g., `human_action`, `scene`), each containing 50 videos (10 prompts Ã— 5 samples).

## ğŸ“ Notes

*   **GPU Usage**: The scripts default to using `GPU_ID=0`. You can change this in the scripts or override it by setting `CUDA_VISIBLE_DEVICES` when running the command.
*   **Parameters**: Default inference parameters (Steps=40, K=5, FPS=16) are set in the scripts but can be modified as needed.
